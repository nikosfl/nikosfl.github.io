---
layout: post
title: Identifying Saliency for Movie Summarization
subtitle: let's create some trailers!
use-site-title: true
permalink: movie_summarization
involved: 2014
---

Humans have a unique capability of quickly identifying points of interests in a visual signal. Being able to efficiently extract, through a computational process, such salient segments in a video would lead to high-quality automated movie summaries. Motivated by neurobiological and psychophysical evidence about the way the human brain performs such actions, we are interested in developing algorithms towards this direction.

My involvement in the particular field is due to a project that I undertook as part of the requirements for the class "Video and Image Analysis and Technology", offered at NTUA in Spring 2014, on movie summarization using attention and perception models. For this project, after implementing some of the techniques proposed in "[Multimodal Saliency and Fusion for Movie Summarization based on Aural, Visual and Textual Attention](http://dx.doi.org/10.1109/TMM.2013.2267205)", I conducted a series of original experiments.

Here is a 30% summary of the short film [The Most Beautiful Thing](https://www.youtube.com/watch?v=IP8psM4LWXk)

and here is a 50% summary of the short film [Losses](https://www.youtube.com/watch?v=BMhXexbDmv8).

If you are interested in the specific methodology, the theoretical background, and the qualitative comparative results - and you know Greek - you can read my [report](/work/classes/projects/eksaminiaia_video.pdf).

<!-- last updated: 2018-09-27 -->
