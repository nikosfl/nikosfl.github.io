---
layout: post
title: Speaker Role Recognition
subtitle: and how to combine it with other speech processing tasks
use-site-title: true
permalink: research/srr
involved: 2018-present
---

Speaker role recognition is the task of assigning a specific role in a speaker-homogeneous segment, where a role is characterized by the task a speaker performs. Broadcast news programs, call centers, therapy sessions, or interviews are some examples of conversational scenarios where each participant performs some well-defined task and thus plays some role. 

The approaches that tackle this task depend on successful pre-processing steps applied on the conversation, such as speaker diarization or Automatic Speech Recognition (ASR). However, in real-world settings, this leads to error propagation. Additionally, knowledge of the roles can be proved useful for those pre-processing steps, as well. For example, the language used by an interviewer is expected to be different than the one used by the interviewee, and this is something which can be ideally exploited by a role-aware ASR system by using role-specific language models. 

What we are trying to do in this research thread is to combine speaker role recognition with other speech processing modules in order both to improve the performance of the role recognition itself and to provide useful information to the module it is combined with. In the paper "Role Annotated Speech Recognition for Conversational Interactions" (to be presented in SLT 2018) we are proposing an end-to-end system which does at the same time the jobs of an ASR, a diarization, and a role recognition module for the case of two speakers. In the paper "[Combined Speaker Clustering and Role Recognition in Conversational Speech](http://dx.doi.org/10.21437/Interspeech.2018-1654)" we are combining a speaker role recognizer with a traditional agglomerative speaker clustering module, achieving improved performance.

<!-- last updated: 2018-09-27 -->
