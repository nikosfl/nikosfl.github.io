---
layout: post
title: Speaker Role Recognition
subtitle: and how to combine it with other speech processing tasks
use-site-title: true
permalink: research/srr
involved: 2018-present
---

Speaker role recognition is the task of assigning a specific role in a speaker-homogeneous segment, where a role is characterized by the task a speaker performs. Broadcast news programs, call centers, therapy sessions, or interviews are some examples of conversational scenarios where each participant performs some well-defined task and thus plays some role. 

<p align="center">
  <img src="/img/roles_eg.png" width="400">  
</p>
<em><font size="-2">
Examples of conversational interactions where speakers assume distinct roles.  
Images from the Noun Project; creators: Nubaia Karim Barsha, Gan Khun Lay, Arafat Uddin, Llisole, ProSymbols
</font></em>


The approaches that tackle this task depend on successful pre-processing steps applied on the conversation, such as speaker diarization or Automatic Speech Recognition (ASR). However, in real-world settings, this leads to error propagation. Additionally, knowledge of the roles can be proved useful for those pre-processing steps, as well. For example, the language used by an interviewer is expected to be different than the one used by the interviewee, and this is something which can be ideally exploited by a role-aware ASR system by using role-specific language models. 

What we are trying to do in this research thread is combine speaker role recognition with other speech processing modules in order both to improve the performance of the role recognition itself and to provide useful contextual information to the module it is combined with. Since, in a real-world scenario, the role recognizer gets the textual information from an ASR system, [here](/work/papers/2019_ICASSP_Role_Specific_ASR.pdf) we propose building role-specific ASR outputs through lattice rescoring, exploiting the rich information in the generic decoding lattice before pruning it. [In this paper](/work/papers/2018_SLT_RASR.pdf) we propose an end-to-end rich transcription system which performs simultaneously the tasks of ASR, diarization, and role recognition for the case of dyadic interactions. [Here](/work/papers/2018_IS_SpeakerClustering.pdf) we combine a speaker role recognizer with a traditional agglomerative speaker clustering module, exploiting information from both the acoustic and linguistic modalities. Finally, [this paper](/work/papers/2020_ODYSSEY_Linguistically_Diarization_Roles.pdf) presents a way to exploit in-domain information about speaker roles in order to improve the performance of a traditional speaker diarization system, answering the question ``which role spoke when".

<!-- last updated: 2021-11-07-->
